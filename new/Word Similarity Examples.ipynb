{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552a8e54",
   "metadata": {},
   "source": [
    "# 1. Word Embeddings with Cosine Similarity using Word2Vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e22d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample sentences\n",
    "sentence1 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "sentence2 = \"A fast brown fox leaps over a sleeping canine.\"\n",
    "\n",
    "# Pre-trained Word2Vec model (download or use your own)\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('word2vec.bin', binary=True)\n",
    "\n",
    "# Tokenize and average word embeddings for each sentence\n",
    "tokens1 = sentence1.lower().split()\n",
    "tokens2 = sentence2.lower().split()\n",
    "vector1 = sum(model[token] for token in tokens1) / len(tokens1)\n",
    "vector2 = sum(model[token] for token in tokens2) / len(tokens2)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_score = cosine_similarity(vector1.reshape(1, -1), vector2.reshape(1, -1))[0, 0]\n",
    "print(f\"Cosine Similarity: {similarity_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e923bdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.8298037648200989\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "\n",
    "# Sample sentences\n",
    "sentence1 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "sentence2 = \"A fast brown fox leaps over a sleeping canine.\"\n",
    "\n",
    "# Download the pre-trained Word2Vec model (only required once)\n",
    "model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# Tokenize and get embeddings for each sentence\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "tokens1 = [token.translate(translator).lower() for token in sentence1.split()]\n",
    "tokens2 = [token.translate(translator).lower() for token in sentence2.split()]\n",
    "\n",
    "# Filter out empty strings after removing punctuation\n",
    "tokens1 = list(filter(None, tokens1))\n",
    "tokens2 = list(filter(None, tokens2))\n",
    "\n",
    "# Calculate embeddings for each token\n",
    "embeddings1 = [model[token] for token in tokens1 if token in model]\n",
    "embeddings2 = [model[token] for token in tokens2 if token in model]\n",
    "\n",
    "# Handle cases where no tokens are in the Word2Vec model\n",
    "if not embeddings1 or not embeddings2:\n",
    "    print(\"No embeddings found for one or both sentences.\")\n",
    "    exit()\n",
    "\n",
    "# Average the embeddings for each sentence\n",
    "vector1 = sum(embeddings1) / len(embeddings1)\n",
    "vector2 = sum(embeddings2) / len(embeddings2)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_score = cosine_similarity(vector1.reshape(1, -1), vector2.reshape(1, -1))\n",
    "print(f\"Cosine Similarity: {similarity_score[0, 0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ccc5b",
   "metadata": {},
   "source": [
    "# 2. BERT and Transformer-based Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "503ba110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e94da8c635e43b7ae7eda134c613bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9935073852539062\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample sentences\n",
    "sentence1 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "sentence2 = \"A fast brown fox leaps over a sleeping canine.\"\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize and get embeddings for each sentence\n",
    "inputs1 = tokenizer(sentence1, return_tensors='pt', padding=True, truncation=True)\n",
    "inputs2 = tokenizer(sentence2, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# Get BERT embeddings\n",
    "with torch.no_grad():\n",
    "    embeddings1 = model(**inputs1).pooler_output\n",
    "    embeddings2 = model(**inputs2).pooler_output\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_score = cosine_similarity(embeddings1, embeddings2)\n",
    "print(f\"Cosine Similarity: {similarity_score.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb4942",
   "metadata": {},
   "source": [
    "# Pros:\n",
    "State-of-the-art performance in various NLP tasks due to deep contextual understanding.\n",
    "Can handle out-of-vocabulary words effectively.\n",
    "# Cons:\n",
    "Computationally expensive and requires significant resources.\n",
    "Slower compared to simpler methods.\n",
    "May require a large amount of training data for fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7b7b7",
   "metadata": {},
   "source": [
    "# 3. Cosine Similarity with TF-IDF Vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2bddca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.2095424038071013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample sentences\n",
    "sentence1 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "sentence2 = \"A fast brown fox leaps over a sleeping canine.\"\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transform sentences into TF-IDF vectors\n",
    "tfidf_matrix = vectorizer.fit_transform([sentence1, sentence2])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_score = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "print(f\"Cosine Similarity: {similarity_score[0, 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcda1d6",
   "metadata": {},
   "source": [
    "# 4.  Siamese Networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43c7627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import gensim.downloader as api\n",
    "\n",
    "\n",
    "# # Sample sentences\n",
    "# sentence1 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "# sentence2 = \"A fast brown fox leaps over a sleeping canine.\"\n",
    "\n",
    "# # Pre-trained Word2Vec model (download or use your own)\n",
    "# model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# # Tokenize and get embeddings for each sentence\n",
    "# tokens1 = sentence1.lower().split()\n",
    "# tokens2 = sentence2.lower().split()\n",
    "# vector1 = np.array([model[token] for token in tokens1])\n",
    "# vector2 = np.array([model[token] for token in tokens2])\n",
    "\n",
    "# # Calculate cosine similarity\n",
    "# similarity_score = cosine_similarity(vector1.reshape(1, -1), vector2.reshape(1, -1))\n",
    "# print(f\"Cosine Similarity: {similarity_score[0, 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83fb5c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codetrade/anaconda3/lib/python3.10/tkinter/__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/tmp/ipykernel_6458/131764056.py\", line 9, in generate_function\n",
      "    results = property_search(location, property_type, bhk, sqft)\n",
      "NameError: name 'property_search' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codetrade/anaconda3/lib/python3.10/tkinter/__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/tmp/ipykernel_6458/131764056.py\", line 9, in generate_function\n",
      "    results = property_search(location, property_type, bhk, sqft)\n",
      "NameError: name 'property_search' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codetrade/anaconda3/lib/python3.10/tkinter/__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/tmp/ipykernel_6458/131764056.py\", line 9, in generate_function\n",
      "    results = property_search(location, property_type, bhk, sqft)\n",
      "NameError: name 'property_search' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codetrade/anaconda3/lib/python3.10/tkinter/__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/tmp/ipykernel_6458/131764056.py\", line 9, in generate_function\n",
      "    results = property_search(location, property_type, bhk, sqft)\n",
      "NameError: name 'property_search' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codetrade/anaconda3/lib/python3.10/tkinter/__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/tmp/ipykernel_6458/131764056.py\", line 9, in generate_function\n",
      "    results = property_search(location, property_type, bhk, sqft)\n",
      "NameError: name 'property_search' is not defined\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "def generate_function():\n",
    "    location = location_entry.get()\n",
    "    property_type = property_type_entry.get()\n",
    "    bhk = bhk_entry.get() if bhk_entry.get() else None\n",
    "    sqft = sqft_entry.get() if sqft_entry.get() else None\n",
    "\n",
    "    results = property_search(location, property_type, bhk, sqft)\n",
    "    # Do something with the results, e.g., display them in a GUI or print them.\n",
    "\n",
    "# Create the GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Property Search\")\n",
    "\n",
    "location_label = tk.Label(root, text=\"Location:\")\n",
    "location_label.pack()\n",
    "location_entry = tk.Entry(root)\n",
    "location_entry.pack()\n",
    "\n",
    "property_type_label = tk.Label(root, text=\"Property Type:\")\n",
    "property_type_label.pack()\n",
    "property_type_entry = tk.Entry(root)\n",
    "property_type_entry.pack()\n",
    "\n",
    "bhk_label = tk.Label(root, text=\"BHK:\")\n",
    "bhk_label.pack()\n",
    "bhk_entry = tk.Entry(root)\n",
    "bhk_entry.pack()\n",
    "\n",
    "sqft_label = tk.Label(root, text=\"SQFT:\")\n",
    "sqft_label.pack()\n",
    "sqft_entry = tk.Entry(root)\n",
    "sqft_entry.pack()\n",
    "\n",
    "search_button = tk.Button(root, text=\"Search\", command=generate_function)\n",
    "search_button.pack()\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c587dac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for 2 bhk flat in New York\n",
      "Searching for house with 1500 sqft in London\n"
     ]
    }
   ],
   "source": [
    "def property_search(question, location, property_type, details=None):\n",
    "    # Validating the question type\n",
    "    if question.lower() not in [\"search\", \"create function\"]:\n",
    "        return \"Invalid question. Please use 'search' or 'create function'.\"\n",
    "\n",
    "    # Validating the property type\n",
    "    property_type = property_type.lower()\n",
    "    if property_type not in [\"flat\", \"house\"]:\n",
    "        return \"Invalid property type. Supported types are 'flat' or 'house'.\"\n",
    "\n",
    "    # Action statements based on the provided statements\n",
    "    if question.lower() == \"search\":\n",
    "        if details is None:\n",
    "            return f\"Invalid details for {property_type} search.\"\n",
    "\n",
    "        if \"bhk\" in details.lower() and property_type == \"flat\":\n",
    "            return f\"Searching for {details} {property_type} in {location}\"\n",
    "        elif \"sqft\" in details.lower() and property_type == \"flat\":\n",
    "            return f\"Searching for {property_type} with {details} in {location}\"\n",
    "        elif \"sqft\" in details.lower() and property_type == \"house\":\n",
    "            return f\"Searching for {property_type} with {details} in {location}\"\n",
    "        else:\n",
    "            return f\"Invalid details for {property_type} search.\"\n",
    "\n",
    "    elif question.lower() == \"create function\":\n",
    "        return \"\"\"\n",
    "def custom_property_search(location, property_type, details):\n",
    "    # Custom function implementation based on location, property_type, and details\n",
    "    pass\n",
    "\"\"\"\n",
    "    else:\n",
    "        return \"Invalid question. Please use 'search' or 'create function'.\"\n",
    "\n",
    "# Example usage:\n",
    "question = \"search\"\n",
    "location = \"New York\"\n",
    "property_type = \"flat\"\n",
    "details = \"2 bhk\"\n",
    "print(property_search(question, location, property_type, details))\n",
    "\n",
    "question = \"search\"\n",
    "location = \"London\"\n",
    "property_type = \"house\"\n",
    "details = \"1500 sqft\"\n",
    "print(property_search(question, location, property_type, details))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc7e907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the house size in sqft at New York? It is 2000 sqft and priced at $300000.\n",
      "How many BHKs are there in the flat located at New York? It is a 2 BHK flat and priced at $200000.\n"
     ]
    }
   ],
   "source": [
    "def question_generate(location, property_type, area, price):\n",
    "    if property_type.lower() == 'house':\n",
    "        return f\"What is the {property_type} size in sqft at {location}? It is {area} sqft and priced at ${price}.\"\n",
    "    elif property_type.lower() == 'flat':\n",
    "        return f\"How many BHKs are there in the {property_type} located at {location}? It is a {area} BHK flat and priced at ${price}.\"\n",
    "    else:\n",
    "        return \"Invalid property type. Please provide 'house' or 'flat'.\"\n",
    "\n",
    "# Example usage:\n",
    "location = \"New York\"\n",
    "house_sqft = 2000\n",
    "house_price = 300000\n",
    "flat_bhk = 2\n",
    "flat_price = 200000\n",
    "print(question_generate(location, \"house\", house_sqft, house_price))\n",
    "print(question_generate(location, \"flat\", flat_bhk, flat_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9834cfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the location: rajkot\n",
      "Enter the property type (house or flat): flat\n",
      "Enter the size in sqft (for house) or BHK (for flat): 2bhk\n",
      "Enter the price: 900\n",
      "Generated Question: How many BHKs are there in the flat located at rajkot? It is a 2bhk BHK flat and priced at $900.\n"
     ]
    }
   ],
   "source": [
    "def question_generate(location, property_type, area, price):\n",
    "    if property_type.lower() == 'house':\n",
    "        return f\"What is the {property_type} size in sqft at {location}? It is {area} sqft and priced at ${price}.\"\n",
    "    elif property_type.lower() == 'flat':\n",
    "        return f\"How many BHKs are there in the {property_type} located at {location}? It is a {area} BHK flat and priced at ${price}.\"\n",
    "    else:\n",
    "        return \"Invalid property type. Please provide 'house' or 'flat'.\"\n",
    "\n",
    "# Ask the user for inputs\n",
    "location = input(\"Enter the location: \")\n",
    "property_type = input(\"Enter the property type (house or flat): \")\n",
    "area = input(\"Enter the size in sqft (for house) or BHK (for flat): \")\n",
    "price = input(\"Enter the price: \")\n",
    "\n",
    "# Generate the question and print it\n",
    "question = question_generate(location, property_type, area, price)\n",
    "print(\"Generated Question:\", question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a74d3a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the location: rajkot\n",
      "Enter the property type (house or flat): flat\n",
      "Enter the size in sqft (for house) or BHK (for flat): 2bhk\n",
      "Enter the price: 9090\n",
      "Generated Question: What is the size of the flat in rajkot? It has 2bhk BHK and is priced at $9090.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def question_generate(location, property_type, area, price):\n",
    "    questions = []\n",
    "    if property_type.lower() == 'house':\n",
    "        questions.append(f\"What is the {property_type} size in sqft at {location}? It is {area} sqft and priced at ${price}.\")\n",
    "        questions.append(f\"How big is the {property_type} at {location}? It covers an area of {area} sqft and costs ${price}.\")\n",
    "    elif property_type.lower() == 'flat':\n",
    "        questions.append(f\"How many BHKs are there in the {property_type} located at {location}? It is a {area} BHK flat and priced at ${price}.\")\n",
    "        questions.append(f\"What is the size of the {property_type} in {location}? It has {area} BHK and is priced at ${price}.\")\n",
    "    else:\n",
    "        return \"Invalid property type. Please provide 'house' or 'flat'.\"\n",
    "\n",
    "    # Select a random question from the list\n",
    "    return random.choice(questions)\n",
    "\n",
    "# Ask the user for inputs\n",
    "location = input(\"Enter the location: \")\n",
    "property_type = input(\"Enter the property type (house or flat): \")\n",
    "area = input(\"Enter the size in sqft (for house) or BHK (for flat): \")\n",
    "price = input(\"Enter the price: \")\n",
    "\n",
    "# Generate the question and print it\n",
    "question = question_generate(location, property_type, area, price)\n",
    "print(\"Generated Question:\", question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4238d13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['antonio superchi', 'antonio tarver', 'antonio torres jurado', 'antonio valdes', 'antonio valdes y fernandez bazan', 'antonio valdez', 'antonio valdés y bazán', 'antonio valdés y fernández bazán', 'antonio valente', 'antonio vitali', 'antonio vivaldi', 'antonio xavier machado e cerveira']\n",
      "743274 mwes\n"
     ]
    }
   ],
   "source": [
    "mwes = open('/home/codetrade/Downloads/CSV/hello/manyterms.lower.txt').read().lower().strip().split('\\n')\n",
    "print(mwes[44444:44456])\n",
    "print(len(mwes), 'mwes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffb59b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codetrade/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1379: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m cvectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m), stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, vocabulary\u001b[38;5;241m=\u001b[39mmwes, lowercase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m X \u001b[38;5;241m=\u001b[39m cvectorizer\u001b[38;5;241m.\u001b[39mfit_transform(patent_texts)\n\u001b[0;32m----> 8\u001b[0m termdf_cv \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39msum(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), columns\u001b[38;5;241m=\u001b[39m\u001b[43mcvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m())\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      9\u001b[0m termdf_cv \u001b[38;5;241m=\u001b[39m termdf_cv\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(termdf_cv\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m25\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "patent_texts = pd.read_csv(\"/home/codetrade/Downloads/CSV/hello/hearst_patterns.155.csv\")\n",
    "\n",
    "cvectorizer = CountVectorizer(ngram_range=(1, 4), stop_words=\"english\", vocabulary=mwes, lowercase=True)\n",
    "X = cvectorizer.fit_transform(patent_texts)\n",
    "termdf_cv = pd.DataFrame(np.sum(X, axis=0), columns=cvectorizer.get_feature_names()).T\n",
    "termdf_cv = termdf_cv.sort_values(by=0, ascending=False)\n",
    "print(termdf_cv.head(25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7e31ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
