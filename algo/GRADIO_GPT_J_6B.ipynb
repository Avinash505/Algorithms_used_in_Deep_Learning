{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ko3J-uXeg2T3"
   },
   "source": [
    "## Using Gradio to wrap a text to text interface around GPT-J-6B\n",
    "\n",
    "Check out the library on [github](https://github.com/gradio-app/gradio-UI) and see the [getting started](https://gradio.app/getting_started.html) page for more demos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npQy3li2g923"
   },
   "source": [
    "### Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NfR2g52--Gus",
    "outputId": "7533a8bf-f063-424c-8af2-28a82780a5ca"
   },
   "outputs": [],
   "source": [
    "# !pip install --quiet gradio\n",
    "# !pip install gardio\n",
    "# !pip install -q git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gardio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgardio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TFGPT2LMHeadModel,GPT2Tokenizer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gardio'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/codetrade/anaconda3/lib/python3.10/site-packages/gradio/routes.py\", line 437, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/codetrade/anaconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1352, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/codetrade/anaconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1077, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/codetrade/anaconda3/lib/python3.10/site-packages/anyio/to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"/home/codetrade/anaconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/codetrade/anaconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/codetrade/anaconda3/lib/python3.10/site-packages/gradio/external.py\", line 403, in query_huggingface_api\n",
      "    raise Error(\n",
      "gradio.exceptions.Error: 'Could not complete request to HuggingFace API, Status Code: 504, Error: Model EleutherAI/gpt-j-6b time out'\n"
     ]
    }
   ],
   "source": [
    "import gardio as gr\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel,GPT2Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "fpnqjQor-Guv",
    "outputId": "c9610515-1c37-4a9b-d70e-c23dddc02d4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codetrade/anaconda3/lib/python3.10/site-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/home/codetrade/anaconda3/lib/python3.10/site-packages/gradio/inputs.py:30: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "/home/codetrade/anaconda3/lib/python3.10/site-packages/gradio/inputs.py:30: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "/home/codetrade/anaconda3/lib/python3.10/site-packages/gradio/interface.py:94: UserWarning: gr.Interface.load() will be deprecated. Use gr.load() instead.\n",
      "  warnings.warn(\"gr.Interface.load() will be deprecated. Use gr.load() instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching model from: https://huggingface.co/EleutherAI/gpt-j-6B\n",
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "title = \"GPT-J-6B\"\n",
    "\n",
    "examples = [\n",
    "    ['The tower is 324 metres (1,063 ft) tall,'],\n",
    "    [\"The Moon's orbit around Earth has\"],\n",
    "    [\"The smooth Borealis basin in the Northern Hemisphere covers 40%\"]\n",
    "]\n",
    "\n",
    "gr.Interface.load(\"huggingface/EleutherAI/gpt-j-6B\",\n",
    "    inputs=gr.inputs.Textbox(lines=5, label=\"Input Text\"),\n",
    "    title=title, examples=examples).launch();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsYULBhZhc0M"
   },
   "source": [
    "#### The model is now live on the gradio.app link shown above. Go ahead and open that in a new tab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xn27MzU0hdS2"
   },
   "source": [
    "Please contact us [here](mailto:team@gradio.app) if you have any questions, or [open an issue](https://github.com/gradio-app/gradio-UI/issues/new/choose) at our github repo.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
